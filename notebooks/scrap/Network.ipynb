{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "\n",
    "from menpo.image import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, ifftshift\n",
    "\n",
    "from menpo.model import PCAModel, ICAModel, NMFModel\n",
    "from menpo.math.decomposition.ica import _batch_ica, negentropy_logcosh\n",
    "from menpo.image import Image\n",
    "from menpo.visualize import print_dynamic, progress_bar_str\n",
    "\n",
    "from alaborticcv2015.utils import pad, crop, multiconvsum, multiconvlist\n",
    "from alaborticcv2015.deepconvkernel.generative import learn_pca_filters, learn_ica_filters \n",
    "\n",
    "\n",
    "class GenerativeDCK():\n",
    "\n",
    "    def __init__(self, learn_filters=learn_pca_filters, n_levels=3,\n",
    "                 n_filters=8, patch_size=(7, 7), mean_centre=False,\n",
    "                 correlation=False, mode='same', boundary='constant'):\n",
    "        self._learn_filters = learn_filters\n",
    "        self.n_levels = n_levels\n",
    "        self.n_filters = n_filters\n",
    "        self.patch_size = patch_size\n",
    "        self.mean_centre = mean_centre\n",
    "        self.correlation = correlation\n",
    "        self.mode = mode\n",
    "        self.boundary = boundary\n",
    "\n",
    "    def learn_network(self, images, group=None, label=None, verbose=False,\n",
    "                      **kwargs):\n",
    "        if verbose:\n",
    "            string = '- Learning network'\n",
    "        # initialize level_image and list of filters\n",
    "        level_images = images\n",
    "        self.filters = []\n",
    "        for j in range(self.n_levels):\n",
    "            if verbose:\n",
    "                print_dynamic('{}: {}'.format(\n",
    "                    string, progress_bar_str(j/self.n_levels, show_bar=True)))\n",
    "            # extract level patches\n",
    "            level_patches = self._extract_patches(level_images, group=group,\n",
    "                                                  label=label)\n",
    "            # learn level filters\n",
    "            level_filters = self._learn_filters(level_patches, self.n_filters,\n",
    "                                                **kwargs)\n",
    "            # compute level responses lists\n",
    "            level_images = self._compute_filter_responses(level_images,\n",
    "                                                          level_filters)\n",
    "            # save level filters\n",
    "            self.filters.append(level_filters)\n",
    "        if verbose:\n",
    "            print_dynamic('{}: Done!\\n'.format(string))\n",
    "\n",
    "    def _extract_patches(self, images, group=None, label=None):\n",
    "        patches = [i.extract_patches_around_landmarks(\n",
    "                   group=group, label=label, patch_size=self.patch_size)\n",
    "                   for i in images]\n",
    "        return [p for ps in patches for p in ps]\n",
    "\n",
    "    def _compute_filter_responses(self, images, filters):\n",
    "        images = [multiconvlist(i, filters, mean_centre=self.mean_centre,\n",
    "                                correlation=self.correlation, mode=self.mode,\n",
    "                                boundary=self.boundary) for i in images]\n",
    "        return [i for imgs in images for i in imgs]\n",
    "\n",
    "    def learn_kernel(self, level=None, ext_shape=None):\n",
    "        kernel = 1\n",
    "        for level_filters in self.filters[:level]:\n",
    "            k = 0\n",
    "            for f in level_filters:\n",
    "                if ext_shape is not None:\n",
    "                    f_pixels = pad(f.pixels, ext_shape)\n",
    "                else:\n",
    "                    f_pixels = f.pixels\n",
    "                fft_f = fft2(f_pixels)\n",
    "                k += fft_f.conj() * fft_f\n",
    "            kernel *= k\n",
    "        return Image(kernel)\n",
    "\n",
    "    def compute_network_response(self, image, level=None):\n",
    "        images = [image]\n",
    "        for level_filters in self.filters[:level]:\n",
    "            images = self._compute_filter_responses(images, level_filters)\n",
    "        return self._list_to_image(images)\n",
    "\n",
    "    @classmethod\n",
    "    def _list_to_image(cls, images):\n",
    "        img = images[0]\n",
    "        n_ch, h, w = img.pixels.shape\n",
    "        pixels = np.zeros((len(images) * n_ch, h, w))\n",
    "        for j, i in enumerate(images):\n",
    "            ind = j * n_ch\n",
    "            pixels[ind:ind+n_ch] = i.pixels\n",
    "        img = Image(pixels)\n",
    "        img.landmarks = images[0].landmarks\n",
    "        return img\n",
    "\n",
    "    def compute_kernel_response(self, i, level=None):\n",
    "        # extended shape\n",
    "        i_shape = np.asarray(i.shape)\n",
    "        f_shape = np.asarray(self.filters[0][0].shape)\n",
    "        ext_shape = i_shape + f_shape - 1\n",
    "\n",
    "        # extend image and filter\n",
    "        ext_i = pad(i.pixels, ext_shape, mode=self.boundary)\n",
    "\n",
    "        # compute ffts of extended image and extended filter\n",
    "        fft_ext_i = fft2(ext_i)\n",
    "        # compute deep convolutional kernel\n",
    "        fft_ext_f = self.learn_kernel(level=level, ext_shape=ext_shape).pixels\n",
    "\n",
    "        # compute extended convolution in Fourier domain\n",
    "        fft_ext_c = fft_ext_f**0.5 * fft_ext_i\n",
    "\n",
    "        # compute ifft of extended convolution\n",
    "        ext_c =  np.real(ifft2(fft_ext_c))\n",
    "\n",
    "        if self.mode is 'full': \n",
    "            c = Image(ext_c)\n",
    "            c.landmarks = i.landmarks\n",
    "            for key in c.landmarks.keys():\n",
    "                c.landmarks[key].lms.points += (f_shape - 1) // 2  \n",
    "        elif self.mode is 'same':\n",
    "            c = Image(crop(ext_c, i_shape))\n",
    "            c.landmarks = i.landmarks\n",
    "        elif self.mode is 'valid':\n",
    "            c = Image(crop(ext_c, i_shape - f_shape + 1))\n",
    "            c.landmarks = i.landmarks\n",
    "            for key in c.landmarks.keys():\n",
    "                c.landmarks[key].lms.points -= (f_shape - 1) // 2  \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"mode={}, is not supported. The only supported \"\n",
    "                \"modes are: 'full', 'same' and 'valid'.\".format(mode)) \n",
    "\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, ifftshift\n",
    "\n",
    "from menpo.model import PCAModel, ICAModel, NMFModel\n",
    "from menpo.math.decomposition.ica import _batch_ica, negentropy_logcosh\n",
    "from menpo.image import Image\n",
    "from menpo.visualize import print_dynamic, progress_bar_str\n",
    "\n",
    "from alaborticcv2015.utils import pad, crop, multiconvsum, multiconvlist\n",
    "from alaborticcv2015.deepconvkernel.generative import learn_pca_filters, learn_ica_filters \n",
    "\n",
    "\n",
    "class GenerativeDCK():\n",
    "\n",
    "    def __init__(self, learn_filters=learn_pca_filters, n_levels=3,\n",
    "                 n_filters=8, patch_size=(7, 7), mean_centre=False,\n",
    "                 correlation=False, mode='same', boundary='constant'):\n",
    "        self._learn_filters = learn_filters\n",
    "        self.n_levels = n_levels\n",
    "        self.n_filters = n_filters\n",
    "        self.patch_size = patch_size\n",
    "        self.mean_centre = mean_centre\n",
    "        self.correlation = correlation\n",
    "        self.mode = mode\n",
    "        self.boundary = boundary\n",
    "\n",
    "    def learn_network(self, images, group=None, label=None, verbose=False,\n",
    "                      **kwargs):\n",
    "        if verbose:\n",
    "            string = '- Learning network'\n",
    "        # initialize level_image and list of filters\n",
    "        level_images = images\n",
    "        self.filters = []\n",
    "        for j in range(self.n_levels):\n",
    "            if verbose:\n",
    "                print_dynamic('{}: {}'.format(\n",
    "                    string, progress_bar_str(j/self.n_levels, show_bar=True)))\n",
    "            # extract level patches\n",
    "            level_patches = self._extract_patches(level_images, group=group,\n",
    "                                                  label=label)\n",
    "            # learn level filters\n",
    "            level_filters = self._learn_filters(level_patches, self.n_filters,\n",
    "                                                **kwargs)\n",
    "            # compute level responses lists\n",
    "            level_images = self._compute_filter_responses(level_images,\n",
    "                                                          level_filters)\n",
    "            # save level filters\n",
    "            self.filters.append(level_filters)\n",
    "        if verbose:\n",
    "            print_dynamic('{}: Done!\\n'.format(string))\n",
    "\n",
    "    def _extract_patches(self, images, group=None, label=None):\n",
    "        patches = [i.extract_patches_around_landmarks(\n",
    "                   group=group, label=label, patch_size=self.patch_size)\n",
    "                   for i in images]\n",
    "        return [p for ps in patches for p in ps]\n",
    "\n",
    "    def _compute_filter_responses(self, images, filters):\n",
    "        images = [multiconvlist(i, filters, mean_centre=self.mean_centre,\n",
    "                                correlation=self.correlation, mode=self.mode,\n",
    "                                boundary=self.boundary) for i in images]\n",
    "        return [i for imgs in images for i in imgs]\n",
    "\n",
    "    def learn_kernel(self, level=None):\n",
    "        kernel = 1\n",
    "        for level_filters in self.filters[:level]:\n",
    "            k = 0\n",
    "            for f in level_filters:\n",
    "                fft_f = fft2(f.pixels)\n",
    "                k += fft_f.conj() * fft_f\n",
    "            kernel *= k\n",
    "        return Image(kernel)\n",
    "\n",
    "    def compute_network_response(self, image, level=None):\n",
    "        images = [image]\n",
    "        for level_filters in self.filters[:level]:\n",
    "            images = self._compute_filter_responses(images, level_filters)\n",
    "        return self._list_to_image(images)\n",
    "\n",
    "    @classmethod\n",
    "    def _list_to_image(cls, images):\n",
    "        img = images[0]\n",
    "        n_ch, h, w = img.pixels.shape\n",
    "        pixels = np.zeros((len(images) * n_ch, h, w))\n",
    "        for j, i in enumerate(images):\n",
    "            ind = j * n_ch\n",
    "            pixels[ind:ind+n_ch] = i.pixels\n",
    "        img = Image(pixels)\n",
    "        img.landmarks = images[0].landmarks\n",
    "        return img\n",
    "\n",
    "    def compute_kernel_response(self, i, level=None):\n",
    "        # extended shape\n",
    "        i_shape = np.asarray(i.shape)\n",
    "        f_shape = np.asarray(self.filters[0][0].shape)\n",
    "        ext_shape = i_shape + f_shape - 1\n",
    "\n",
    "        # extend image and filter\n",
    "        ext_i = pad(i.pixels, ext_shape, mode=self.boundary)\n",
    "\n",
    "        # compute ffts of extended image and extended filter\n",
    "        fft_ext_i = fft2(ext_i)\n",
    "        # compute deep convolutional kernel\n",
    "        fft_ext_f = self.learn_kernel(level=level, ext_shape=ext_shape).pixels\n",
    "\n",
    "        # compute extended convolution in Fourier domain\n",
    "        fft_ext_c = fft_ext_f**0.5 * fft_ext_i\n",
    "\n",
    "        # compute ifft of extended convolution\n",
    "        ext_c =  np.real(ifft2(fft_ext_c))\n",
    "\n",
    "        if self.mode is 'full': \n",
    "            c = Image(ext_c)\n",
    "            c.landmarks = i.landmarks\n",
    "            for key in c.landmarks.keys():\n",
    "                c.landmarks[key].lms.points += (f_shape - 1) // 2  \n",
    "        elif self.mode is 'same':\n",
    "            c = Image(crop(ext_c, i_shape))\n",
    "            c.landmarks = i.landmarks\n",
    "        elif self.mode is 'valid':\n",
    "            c = Image(crop(ext_c, i_shape - f_shape + 1))\n",
    "            c.landmarks = i.landmarks\n",
    "            for key in c.landmarks.keys():\n",
    "                c.landmarks[key].lms.points -= (f_shape - 1) // 2  \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"mode={}, is not supported. The only supported \"\n",
    "                \"modes are: 'full', 'same' and 'valid'.\".format(mode)) \n",
    "\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import menpo.io as mio\n",
    "from menpo.landmark import labeller, ibug_face_66\n",
    "\n",
    "training_images = []\n",
    "for i in mio.import_images('/data/PhD/DataBases/faces/lfpw/trainset/', verbose=True, \n",
    "                           max_images=25):\n",
    "    \n",
    "    i.crop_to_landmarks_proportion_inplace(1)\n",
    "    i = i.rescale_landmarks_to_diagonal_range(100)\n",
    "    labeller(i, 'PTS', ibug_face_66)\n",
    "    if i.n_channels == 3:\n",
    "        i = i.as_greyscale(mode='average')\n",
    "    training_images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpo.visualize import visualize_images\n",
    "\n",
    "visualize_images(training_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dck = GenerativeDCK(learn_filters=learn_pca_filters, n_filters=8,\n",
    "                    patch_size=(7, 7), n_levels=2, mean_centre=False,\n",
    "                    correlation=False, mode='full', boundary='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dck.learn_network(training_images, group='ibug_face_66', mean_centre=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(dck.filters[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = Image(np.real(fftshift(ifft2(dck.learn_kernel(level=None).pixels))))\n",
    "k.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(i, f, mean_centre=False, correlation=False, mode='same', \n",
    "         boundary='constant'):\n",
    "    if mean_centre:\n",
    "        i = i.copy()\n",
    "        f = f.copy()\n",
    "        i.mean_centre_inplace()\n",
    "        f.mean_centre_inplace()\n",
    "        \n",
    "    if correlation:\n",
    "        f.pixels = f.pixels[:, ::-1, ::-1]\n",
    "    \n",
    "    # extended shape\n",
    "    i_shape = np.asarray(i.shape)\n",
    "    f_shape = np.asarray(f.shape)\n",
    "    ext_shape = i_shape + f_shape - 1\n",
    "\n",
    "    # extend image and filter\n",
    "    ext_i = pad(i.pixels, ext_shape, mode=boundary)\n",
    "    ext_f = pad(f.pixels, ext_shape)\n",
    "\n",
    "    # compute ffts of extended image and extended filter\n",
    "    fft_ext_i = fft2(ext_i)\n",
    "    fft_ext_f = fft2(ext_f)\n",
    "\n",
    "    # compute extended convolution in Fourier domain\n",
    "    fft_ext_c = fft_ext_f * fft_ext_i\n",
    "\n",
    "    # compute ifft of extended convolution\n",
    "    ext_c = ifftshift(ifft2(fft_ext_c), axes=(-2, -1))\n",
    "\n",
    "    if mode is 'full': \n",
    "        c = Image(ext_c)\n",
    "        c.landmarks = i.landmarks\n",
    "        for key in c.landmarks.keys():\n",
    "            c.landmarks[key].lms.points += (f_shape - 1) // 2  \n",
    "    elif mode is 'same':\n",
    "        c = Image(crop(ext_c, i_shape))\n",
    "        c.landmarks = i.landmarks\n",
    "    elif mode is 'valid':\n",
    "        c = Image(crop(ext_c, i_shape - f_shape + 1))\n",
    "        c.landmarks = i.landmarks\n",
    "        for key in c.landmarks.keys():\n",
    "            c.landmarks[key].lms.points -= (f_shape - 1) // 2  \n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"mode={}, is not supported. The only supported \"\n",
    "            \"modes are: 'full', 'same' and 'valid'.\".format(mode)) \n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from menpo.feature import imgfeature\n",
    "\n",
    "@imgfeature\n",
    "def deep_kernel_features(img, level=None):\n",
    "    feature = dck.compute_kernel_response(img, level=level)\n",
    "    return feature\n",
    "\n",
    "@imgfeature\n",
    "def deep_kernel_features2(img, level=None):\n",
    "    feature = Image(conv(img, k, mode='same').pixels)\n",
    "    feature.landmarks = img.landmarks\n",
    "    return feature\n",
    "\n",
    "@imgfeature\n",
    "def deep_network_features(img, level=None):\n",
    "    feature = dck.compute_network_response(img, level=level)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images([deep_network_features(i, level=None) for i in training_images[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images([Image(np.abs(deep_kernel_features2(i, level=None).pixels)) \n",
    "                  for i in training_images[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.aam.base import build_reference_frame\n",
    "from menpo.shape import mean_pointcloud\n",
    "from menpo.transform import PiecewiseAffine\n",
    "\n",
    "# build reference frame\n",
    "shapes = [i.landmarks['PTS'].lms for i in training_images]\n",
    "mean_shape = mean_pointcloud(shapes)\n",
    "reference_frame = build_reference_frame(mean_shape)\n",
    "\n",
    "# warp images\n",
    "transforms = [PiecewiseAffine(reference_frame.landmarks['source'].lms, s) for s in shapes]\n",
    "warped_images = [i.warp_to_mask(reference_frame.mask, t) for (i, t) in zip(training_images, transforms)]\n",
    "\n",
    "img1 = warped_images[1]\n",
    "img2 = warped_images[2]\n",
    "\n",
    "print img1.shape\n",
    "print img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = img1.shape\n",
    "\n",
    "v1n = crop(deep_network_features(Image(img1.pixels)).pixels, shape)\n",
    "v2n = crop(deep_network_features(Image(img2.pixels)).pixels, shape)\n",
    "dotn = v1n.ravel().T.dot(v2n.ravel()) \n",
    "\n",
    "vn = crop(deep_network_features(Image(img1.pixels - img2.pixels)).pixels, shape)\n",
    "l2n = vn.ravel().T.dot(vn.ravel())\n",
    "\n",
    "v1k = deep_kernel_features2(Image(img1.pixels)).pixels\n",
    "v2k = deep_kernel_features2(Image(img2.pixels)).pixels\n",
    "dotk = v1k.ravel().conj().T.dot(v2k.ravel()) \n",
    "\n",
    "vk = deep_kernel_features2(Image(img1.pixels - img2.pixels)).pixels\n",
    "l2k = vk.ravel().conj().T.dot(vk.ravel())\n",
    "\n",
    "print 'Dot Ratio:', dotn / dotk\n",
    "print 'L2 Ratio:', l2n / l2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dotn\n",
    "print dotk\n",
    "\n",
    "print l2n\n",
    "print l2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import menpo.io as mio\n",
    "from menpo.landmark import labeller, ibug_face_49, ibug_face_66_trimesh\n",
    "\n",
    "test_images = []\n",
    "for i in mio.import_images('/data/PhD/DataBases/faces/afw/', verbose=True, \n",
    "                           max_images=10):\n",
    "    \n",
    "    i.crop_to_landmarks_proportion_inplace(1)\n",
    "    i = i.rescale_landmarks_to_diagonal_range(100)\n",
    "    labeller(i, 'PTS', ibug_face_49)\n",
    "    labeller(i, 'PTS', ibug_face_66)\n",
    "    labeller(i, 'PTS', ibug_face_66_trimesh)\n",
    "    if i.n_channels == 3:\n",
    "        i = i.as_greyscale(mode='average')\n",
    "    test_images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpo.feature import no_op, fast_dsift\n",
    "from alabortijcv2015.aam import GlobalAAMBuilder\n",
    "\n",
    "builder = GlobalAAMBuilder(features=deep_kernel_features2, diagonal=100, \n",
    "                           scale_shapes=False, scales=(1, .5))\n",
    "aam = builder.build(training_images, group='ibug_face_66', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.visualize import visualize_appearance_model\n",
    "\n",
    "visualize_appearance_model(aam.appearance_models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from alabortijcv2015.aam import StandardAAMFitter\n",
    "from alabortijcv2015.aam.algorithm import SIC, AIC, MAIC\n",
    "                  \n",
    "fitter = StandardAAMFitter(aam, algorithm_cls=AIC, n_shape=[3, 6], \n",
    "                           n_appearance=[100, 100], sampling_step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)\n",
    "\n",
    "fitter_results = []\n",
    "\n",
    "for j, i in enumerate(test_images[:10]):\n",
    "    \n",
    "    gt_s = i.landmarks['ibug_face_66'].lms\n",
    "    s = fitter.perturb_shape(gt_s, noise_std=0.04)\n",
    "    \n",
    "    fr = fitter.fit(i, s, gt_shape=gt_s, max_iters=20, map_inference=False)\n",
    "    fr.downscale = 0.5\n",
    "    \n",
    "    fitter_results.append(fr)\n",
    "    \n",
    "    print 'Image: ', j\n",
    "    print fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)\n",
    "\n",
    "fitter_results = []\n",
    "\n",
    "for j, i in enumerate(test_images[:10]):\n",
    "    \n",
    "    gt_s = i.landmarks['ibug_face_66'].lms\n",
    "    s = fitter.perturb_shape(gt_s, noise_std=0.04)\n",
    "    \n",
    "    fr = fitter.fit(i, s, gt_shape=gt_s, max_iters=20, map_inference=False)\n",
    "    fr.downscale = 0.5\n",
    "    \n",
    "    fitter_results.append(fr)\n",
    "    \n",
    "    print 'Image: ', j\n",
    "    print fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.visualize import visualize_fitting_results\n",
    "    \n",
    "visualize_fitting_results(fitter_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
